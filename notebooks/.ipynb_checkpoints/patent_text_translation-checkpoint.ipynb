{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patent text translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "As shown in the notebook `text_data_exploration.ipynb`, EP full text data is available for patents in English, French and German."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /home/antoine/.local/lib/python3.6/site-packages (3.5)\n",
      "Requirement already satisfied: joblib in /home/antoine/.local/lib/python3.6/site-packages (from nltk) (0.16.0)\n",
      "Requirement already satisfied: regex in /home/antoine/.local/lib/python3.6/site-packages (from nltk) (2020.7.14)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from nltk) (7.0)\n",
      "Requirement already satisfied: tqdm in /home/antoine/.local/lib/python3.6/site-packages (from nltk) (4.45.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting googletrans\n",
      "  Downloading googletrans-3.0.0.tar.gz (17 kB)\n",
      "Collecting httpx==0.13.3\n",
      "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
      "\u001b[K     |████████████████████████████████| 55 kB 743 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet==3.* in /usr/lib/python3/dist-packages (from httpx==0.13.3->googletrans) (3.0.4)\n",
      "Collecting rfc3986<2,>=1.3\n",
      "  Downloading rfc3986-1.4.0-py2.py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: idna==2.* in /usr/lib/python3/dist-packages (from httpx==0.13.3->googletrans) (2.6)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx==0.13.3->googletrans) (2018.1.18)\n",
      "Collecting httpcore==0.9.*\n",
      "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 296 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting hstspreload\n",
      "  Downloading hstspreload-2020.8.18-py3-none-any.whl (938 kB)\n",
      "\u001b[K     |████████████████████████████████| 938 kB 26.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sniffio\n",
      "  Downloading sniffio-1.1.0-py3-none-any.whl (4.5 kB)\n",
      "Collecting h11<0.10,>=0.8\n",
      "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 672 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting h2==3.*\n",
      "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 703 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting contextvars>=2.1; python_version < \"3.7\"\n",
      "  Downloading contextvars-2.4.tar.gz (9.6 kB)\n",
      "Collecting hpack<4,>=3.0\n",
      "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Collecting hyperframe<6,>=5.2.0\n",
      "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting immutables>=0.9\n",
      "  Downloading immutables-0.14-cp36-cp36m-manylinux1_x86_64.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 1.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: googletrans, contextvars\n",
      "  Building wheel for googletrans (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for googletrans: filename=googletrans-3.0.0-py3-none-any.whl size=15737 sha256=e32bf04533120798d1fa016915ee903fd205e82747e3446acf643b3f8a625fc2\n",
      "  Stored in directory: /home/antoine/.cache/pip/wheels/06/a1/90/75375ea9aff253a4803b2356007f64aecb6ce2f1e46a0aa9ba\n",
      "  Building wheel for contextvars (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for contextvars: filename=contextvars-2.4-py3-none-any.whl size=7665 sha256=cbcdc0f745d61b6c87e0ca2b61949d3a68d94f0c42e662a123ee53fefb344c9f\n",
      "  Stored in directory: /home/antoine/.cache/pip/wheels/41/11/53/911724983aa48deb94792432e14e518447212dd6c5477d49d3\n",
      "Successfully built googletrans contextvars\n",
      "Installing collected packages: rfc3986, h11, immutables, contextvars, sniffio, hpack, hyperframe, h2, httpcore, hstspreload, httpx, googletrans\n",
      "Successfully installed contextvars-2.4 googletrans-3.0.0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2020.8.18 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 immutables-0.14 rfc3986-1.4.0 sniffio-1.1.0\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3.6 install nltk\n",
    "!pip3.6 install googletrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk import sent_tokenize\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/antoine/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# according to the doc, step required\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = pd.read_csv('../data/ep_full_text_database/2020_edition/EP0000000.txt',\n",
    "                          sep = '\\t',  header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publication_authority</th>\n",
       "      <th>publication_number</th>\n",
       "      <th>publication_kind</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>language_text_component</th>\n",
       "      <th>text_type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EP</td>\n",
       "      <td>2</td>\n",
       "      <td>A1</td>\n",
       "      <td>1978-12-20</td>\n",
       "      <td>de</td>\n",
       "      <td>TITLE</td>\n",
       "      <td>Tetrahydrofuran-Derivate, Verfahren zu ihrer H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EP</td>\n",
       "      <td>2</td>\n",
       "      <td>A1</td>\n",
       "      <td>1978-12-20</td>\n",
       "      <td>en</td>\n",
       "      <td>TITLE</td>\n",
       "      <td>Tetrahydrofurane derivatives, processes for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EP</td>\n",
       "      <td>2</td>\n",
       "      <td>A1</td>\n",
       "      <td>1978-12-20</td>\n",
       "      <td>fr</td>\n",
       "      <td>TITLE</td>\n",
       "      <td>Dérivés du tétrahydrofuranne, leurs procédés d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EP</td>\n",
       "      <td>2</td>\n",
       "      <td>A1</td>\n",
       "      <td>1978-12-20</td>\n",
       "      <td>de</td>\n",
       "      <td>ABSTR</td>\n",
       "      <td>&lt;p id=\"pa01\" num=\"0001\"&gt;Die vorliegende Erfind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EP</td>\n",
       "      <td>2</td>\n",
       "      <td>A1</td>\n",
       "      <td>1978-12-20</td>\n",
       "      <td>de</td>\n",
       "      <td>DESCR</td>\n",
       "      <td>&lt;p id=\"p0001\" num=\"0001\"&gt;Die vorliegende Erfin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  publication_authority  publication_number publication_kind publication_date  \\\n",
       "0                    EP                   2               A1       1978-12-20   \n",
       "1                    EP                   2               A1       1978-12-20   \n",
       "2                    EP                   2               A1       1978-12-20   \n",
       "3                    EP                   2               A1       1978-12-20   \n",
       "4                    EP                   2               A1       1978-12-20   \n",
       "\n",
       "  language_text_component text_type  \\\n",
       "0                      de     TITLE   \n",
       "1                      en     TITLE   \n",
       "2                      fr     TITLE   \n",
       "3                      de     ABSTR   \n",
       "4                      de     DESCR   \n",
       "\n",
       "                                                text  \n",
       "0  Tetrahydrofuran-Derivate, Verfahren zu ihrer H...  \n",
       "1  Tetrahydrofurane derivatives, processes for th...  \n",
       "2  Dérivés du tétrahydrofuranne, leurs procédés d...  \n",
       "3  <p id=\"pa01\" num=\"0001\">Die vorliegende Erfind...  \n",
       "4  <p id=\"p0001\" num=\"0001\">Die vorliegende Erfin...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample.columns = ['publication_authority', # will always have the value \"EP\"\n",
    "                'publication_number', # a seven-digit number\n",
    "                'publication_kind', # see https://www.epo.org/searching-for-patents/helpful-resources/first-time-here/definitions.html for help.\n",
    "                'publication_date', # in format YYYY-MM-DD\n",
    "                'language_text_component', # de, en, fr; xx means unknown\n",
    "                'text_type', # TITLE, ABSTR, DESCR, CLAIM, AMEND, ACSTM, SREPT, PDFEP\n",
    "                'text' # it contains, where appropriate, XML tags for better structure. You will find the DTD applicable to all parts of the publication at: http://docs.epoline.org/ebd/doc/ep-patent-document-v1-5.dtd\n",
    "               ]\n",
    "data_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translating patent text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en    546740\n",
       "de    444896\n",
       "fr    336723\n",
       "xx     51157\n",
       "Name: language_text_component, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample.language_text_component.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dispositif pour soulever'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a sample patent title in French\n",
    "condition1 = data_sample.text_type == 'TITLE'\n",
    "condition2 = data_sample.language_text_component == 'fr'\n",
    "df = data_sample[condition1 & condition2]['text'].to_frame()\n",
    "example_fr_xml = df.iloc[111]['text']\n",
    "example_fr_xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text_to_translate, source_language, target_language):\n",
    "    \"\"\"Machine translation using the Google translate API\"\"\"\n",
    "    translator = Translator()\n",
    "    translatedText = translator.translate(text_to_translate, src=source_language, dest=target_language)\n",
    "    return translatedText.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Device for lifting'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(example_fr_xml, 'fr', 'en')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
