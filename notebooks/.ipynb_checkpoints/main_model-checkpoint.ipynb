{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"Configuration\"\"\"\n",
    "    \n",
    "    # Magic numbers\n",
    "    LAST_YEAR_TO_RECEIVE_CITAITONS = 2018\n",
    "    PERCENTAGE_TOP_PATENTS = 0.01\n",
    "\n",
    "    # PASTAT_variables \n",
    "    VAR_APPLN_ID = 'appln_id'\n",
    "    VAR_DOCDC_FAMILY_ID = 'docdb_family_id'\n",
    "    VAR_CITED_DOCDB_FAM_ID = 'cited_docdb_family_id'\n",
    "    VAR_APPLN_FILLING_YEAR = 'appln_filing_year'\n",
    "    VAR_NB_CITING_DOCDB_FAM = 'nb_citing_docdb_fam'\n",
    "    VAR_EARLIEST_FILLING_DATE = 'earliest_filing_date'\n",
    "    VAR_EARLIEST_FILING_YEAR = 'earliest_filing_year'\n",
    "\n",
    "    # Computed variables\n",
    "    NEW_VAR_CITING_DOCDB_FAM_IDS = 'citing_docdb_families_ids'\n",
    "    NEW_VAR_NB_CITING_DOCDB_FAM_BY_YEAR = 'nb_citing_docdb_fam_by_year'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PATSTAT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of the PATSTAT data previously retrieved with the data_extraction_from_PATSTAT.ipynb notebook\n",
    "output_files_prefix = \"wind_tech_1990_2020_with_publications\"\n",
    "pre = '../data/raw/' + output_files_prefix\n",
    "suf = '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For convenience, we store all the data retrieved into a data object.\n",
    "data = {'_table_main_patent_infos': pd.read_csv(pre + '_table_main_patent_infos' + suf, low_memory=False),\n",
    "       '_table_cpc': pd.read_csv(pre + '_table_cpc' + suf, low_memory=False), \n",
    "       '_table_patentees_info': pd.read_csv(pre + '_table_patentees_info' + suf, low_memory=False),\n",
    "       '_table_backward_docdb_citations': pd.read_csv(pre + '_table_backward_docdb_citations' + suf, low_memory=False),\n",
    "       '_table_forward_docdb_citations': pd.read_csv(pre + '_table_forward_docdb_citations' + suf, low_memory=False)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCleaning:\n",
    "    \"\"\"Data cleaning methods\"\"\"\n",
    "    \n",
    "    def __init__():\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def _correct_JP_data(self):\n",
    "        \"\"\"Correction for Japanese patent data, in line with the literature\"\"\"\n",
    "        # Do # Update the list of ids\n",
    "        self = self.__update_patent_fam_ids() # Storing ids and filtering datasets\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    #def _keep_only_EP_patents(self):\n",
    "    #    \"\"\"We filter the data to keep only EU patents (not only EP)\"\"\"\n",
    "    #    \n",
    "    #    # Local variables for simplicity\n",
    "    #    df_main = self.data['_table_main_patent_infos']\n",
    "    #    condition = df_main[''].isin(Config.EU_authorities)\n",
    "    #    df_main = df_main[condition]\n",
    "    #    self = self.__update_patent_fam_ids() # Storing ids and filtering datasets\n",
    "    #    return self\n",
    "    \n",
    "    def _normalise(self):\n",
    "        \"\"\"Normalisation of the data accross years and sectors, to cater for **patent explosion**\"\"\"\n",
    "        # Do # Update the list of ids\n",
    "        self = self.__update_patent_fam_ids() # Storing ids and filtering datasets\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def _select_one_patent_per_family(self):\n",
    "        \"\"\"In order to select only patent of interest, as well as\n",
    "        saving computationnal power, we select only the earliest patent by\n",
    "        family\"\"\"\n",
    "        \n",
    "        # Local variables for simplicity\n",
    "        df_main = self.data['_table_main_patent_infos']\n",
    "        df_cpc = self.data['_table_cpc']\n",
    "        df_patentees = self.data['_table_patentees_info']\n",
    "        \n",
    "        # Filtering \n",
    "        df_main.sort_values(by = Config.VAR_EARLIEST_FILLING_DATE,inplace = True)\n",
    "        df_main.drop_duplicates(subset = [Config.VAR_DOCDC_FAMILY_ID],\n",
    "                                keep = 'first',\n",
    "                                inplace = True)\n",
    "        \n",
    "        # Storing ids and filtering datasets\n",
    "        self = self.__update_patent_fam_ids()   \n",
    "        return self\n",
    "    \n",
    "\n",
    "    def _select_breakthrough_patents(self):\n",
    "        \"\"\"Filtering the data to keep only breakthrough patents\"\"\"\n",
    "        \n",
    "        # Unpacking some variables for clarity\n",
    "        X = Config.PERCENTAGE_TOP_PATENTS\n",
    "        df = self.data['_table_main_patent_infos']\n",
    "        \n",
    "        # Selection  of the top patents\n",
    "        filtered_df = pd.DataFrame()\n",
    "        for year in df[Config.VAR_EARLIEST_FILING_YEAR].unique().tolist():\n",
    "            df_year = df[df[Config.VAR_EARLIEST_FILING_YEAR] == year]\n",
    "            df_year.sort_values(by = Config.VAR_NB_CITING_DOCDB_FAM,\n",
    "                                ascending = False,\n",
    "                                inplace = True)\n",
    "            nb_top_patent_given_year = int(math.ceil(X*len(df_year))) # Needs rounding up\n",
    "            df_year = df_year.head(nb_top_patent_given_year)\n",
    "            filtered_df = pd.concat([filtered_df, df_year])\n",
    "            \n",
    "        # Update the table and the list of patent/fam ids\n",
    "        self.data['_table_main_patent_infos'] = filtered_df\n",
    "        \n",
    "        # Storing ids and filtering datasets\n",
    "        self = self.__update_patent_fam_ids()\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def __update_patent_fam_ids(self):\n",
    "        \"\"\"\n",
    "        Storing patents ids and family ids and filtering the datasets\n",
    "        # Filtering the first 3 datasets on the list of patent ids \n",
    "        # Filtering the other 2 datasets on the list of family ids\n",
    "        \"\"\"\n",
    "        \n",
    "        # (1) Update the list of ids (patent ids and family ids)\n",
    "        df_main = self.data['_table_main_patent_infos']\n",
    "        self.patent_ids = df_main[Config.VAR_APPLN_ID].unique().tolist()\n",
    "        self.patent_family_ids = df_main[Config.VAR_DOCDC_FAMILY_ID].unique().tolist()\n",
    "        \n",
    "        # (2) Filter the tables according to the new list of patent ids\n",
    "        def __filter(df, var, list_ids):\n",
    "            \"\"\"Code snippet to filter a dataset according to a list of ids\"\"\"\n",
    "            condition = df[var].isin(list_ids)\n",
    "            return df[condition]\n",
    "        \n",
    "        for key in self.data:\n",
    "            if key in ['_table_main_patent_infos','_table_cpc','_table_patentees_info']:\n",
    "                self.data[key] = __filter(self.data[key], Config.VAR_APPLN_ID, self.patent_ids)\n",
    "            elif key in ['_table_backward_docdb_citations','_table_forward_docdb_citations']:\n",
    "                self.data[key] = __filter(self.data[key], Config.VAR_DOCDC_FAMILY_ID, self.patent_family_ids)\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewMetrics:\n",
    "    \"\"\"Methods to derive new metrics from the data\"\"\"\n",
    "    \n",
    "    def __init__():\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def _get_DOCDB_fam_cites_per_year(self):\n",
    "        \"\"\"Adding a variable to keep track of yearly citations by patent family\"\"\"\n",
    "        \n",
    "        # Unpacking some variables for clarity\n",
    "        df = self.data['_table_main_patent_infos']\n",
    "        citations_by_year = Config.NEW_VAR_NB_CITING_DOCDB_FAM_BY_YEAR\n",
    "        citations_docdb_fam = Config.VAR_NB_CITING_DOCDB_FAM\n",
    "        year = Config.VAR_APPLN_FILLING_YEAR\n",
    "        ref_year = Config.LAST_YEAR_TO_RECEIVE_CITAITONS\n",
    "        \n",
    "        # Compute the metric\n",
    "        df[citations_by_year] = df[citations_docdb_fam]/(ref_year-df[year])\n",
    "        \n",
    "        # Updating the table\n",
    "        self.TABLE_ALL_PATENTS_INFO = df \n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patent object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a patent object. Since the patent will have a long list of attributes, \n",
    "# we stored their attributes in a dictionnary. As a shortcut, we store the main patent key \n",
    "# appln_id as an attribute direclty accesible with patent.appln_id.\n",
    "\n",
    "\n",
    "class Patent:\n",
    "    \n",
    "    def __init__(self, appln_id):\n",
    "        \"\"\"Setting the patent parameters\"\"\"\n",
    "        \n",
    "        self.appln_id:int # as a shortcut we  store the main patent key\n",
    "        self.patent_attributes = {} # Contains the list of the patent's attributes\n",
    "        \n",
    "        # Set instance attributes\n",
    "        self.patent_attributes.update({Config.VAR_APPLN_ID :  appln_id})\n",
    "        self.appln_id = appln_id "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping to OOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a set of methods to reshape the data from the tabular form (as extracted from PATSTAT)\n",
    "# to an object oriented form, where patents are identified and attributes attributed to them.\n",
    "\n",
    "class ReshapingToOOP:\n",
    "    \"\"\"Methods to assign the data to patent objects\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def _create_patent_objects(self):\n",
    "        \"\"\"\n",
    "        Create a Patent object for each patent id and store them in a list\n",
    "        \"\"\"\n",
    "        self.patent_list = []\n",
    "        for patent_id in list(self.patent_ids):\n",
    "            a = Patent(patent_id)\n",
    "            self.patent_list.append(a)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def _assign_data_to_patent_obj(self):\n",
    "        \"\"\"\n",
    "        Once the data has been retrieved from PATSTAT and the patent objects\n",
    "        have been created, we assign the data to the Patent objects\n",
    "        \"\"\"\n",
    "        \n",
    "        def __snippet_store_patent_attributes(table):\n",
    "            \"\"\"\n",
    "            Code snippet to dynamically store attributes \n",
    "            from a Pandas table in a dictionnary\n",
    "            # If a value has several values, then ts stored in a list\n",
    "            \"\"\"\n",
    "            a = {}\n",
    "            for col in list(table):\n",
    "                key = col\n",
    "                value = table[col].unique().tolist()#[0]\n",
    "                value = [x for x in value if (x == x)!=False] # new line\n",
    "                if len(value) == 1:\n",
    "                    value = value[0]\n",
    "                a[key] = value\n",
    "            return a\n",
    "        \n",
    "        # Unpacking some variables\n",
    "        df_main = self.data['_table_main_patent_infos']\n",
    "        df_cpc = self.data['_table_cpc']\n",
    "        df_patentee = self.data['_table_patentees_info']\n",
    "        df_bwd = self.data['_table_backward_docdb_citations']\n",
    "        df_fwd = self.data['_table_forward_docdb_citations']\n",
    "        \n",
    "        # (1) Assigning the data contained in the main table to the patent\n",
    "        # We merge backward citation data to the main table (on family id)\n",
    "        key = Config.VAR_DOCDC_FAMILY_ID\n",
    "        df_main = pd.merge(df_main, df_bwd,how = 'left',left_on = key,right_on = key)\n",
    "        \n",
    "        for patent in self.patent_list:                \n",
    "            for df in [df_main, df_cpc, df_patentee]:  \n",
    "                patent_table = df[df[Config.VAR_APPLN_ID]==patent.appln_id]\n",
    "                d = __snippet_store_patent_attributes(table = patent_table)\n",
    "                patent.patent_attributes.update(d)\n",
    "        \n",
    "        # (2) Assigning forward citations to the patents      \n",
    "        df_fwd.columns = ['A','B','C'] # Random column names\n",
    "        for patent in self.patent_list:\n",
    "            patent_fam_table = df_fwd[df_fwd['A']==patent.patent_attributes[Config.VAR_DOCDC_FAMILY_ID]]\n",
    "            citing_fam = patent_fam_table['B'].unique().tolist()\n",
    "            patent.patent_attributes.update({Config.NEW_VAR_CITING_DOCDB_FAM_IDS :citing_fam})\n",
    "            \n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get citations\n",
    "We use the similarity measure to link the patents in the network. We use direct and indirect citation links: 􏰀\n",
    "* Direct backwards citation (at the patent family level); 􏰀\n",
    "* Co-citations (CC);\n",
    "* Biographic coupling (BC);\n",
    "* Longitudinal coupling (LC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetCitations:\n",
    "    \"\"\"Methods to compute direct and indirect (BC, CC, LC) citations between the patents\"\"\"\n",
    "        \n",
    "    def _get_direct_citations(self):\n",
    "        \"\"\"Get direct backwards citations (at the level of the family level)\"\"\"\n",
    "        \n",
    "        # Unpacking some varibles for clarity\n",
    "        fam = Config.VAR_DOCDC_FAMILY_ID\n",
    "        cited_fam = Config.VAR_CITED_DOCDB_FAM_ID\n",
    "            \n",
    "        # (1) If a patent cites only one family\n",
    "        list1 = [(x,y) for x in self.patent_list for y in self.patent_list \\\n",
    "                 if y.patent_attributes[fam] == x.patent_attributes[cited_fam]]\n",
    "        \n",
    "        # (2) If the patent cites several families (then stored as list)\n",
    "        list2 = [(x,y) for x in self.patent_list for y in self.patent_list \\\n",
    "                 if type(x.patent_attributes[cited_fam]) ==list \\\n",
    "                 if y.patent_attributes[fam] in x.patent_attributes[cited_fam]]\n",
    "        \n",
    "        # Concatenating the two lists to have the direct citations\n",
    "        self.direct_citations = list1 + list2\n",
    "        return self\n",
    "        \n",
    "        \n",
    "    def _get_BC_citations(self):\n",
    "        \"\"\"\n",
    "        # (1) Bibliographic coupling occurs when two works reference a common third work\n",
    "        # (2) The produced list is non directed.\n",
    "        # (3) Can be optimised\n",
    "        \"\"\"\n",
    "            \n",
    "        # Definition of variables\n",
    "        BC = []\n",
    "        a = self.patent_list\n",
    "        all_patent_pairs = [(a[p1], a[p2]) for p1 in range(len(a)) for p2 in range(p1+1,len(a))]\n",
    "\n",
    "        # Computing BC by looping over all pairs of patents\n",
    "        for patent_1, patent_2 in all_patent_pairs:\n",
    "            list_citing_1 = patent_1.patent_attributes[Config.NEW_VAR_CITING_DOCDB_FAM_IDS]\n",
    "            list_citing_2 = patent_2.patent_attributes[Config.NEW_VAR_CITING_DOCDB_FAM_IDS]\n",
    "            common_elements = [x for x in list_citing_1 if x in list_citing_2]\n",
    "            if len(common_elements)>0:\n",
    "                BC.append((patent_1, patent_2))\n",
    "            \n",
    "        # Removing duplicated items in the list\n",
    "        self.BC = list(set(BC)) \n",
    "        return self\n",
    "        \n",
    "        \n",
    "    def _get_CC_citations(self):\n",
    "        \"\"\"\n",
    "        # (1) Co-citation is defined as the frequency with which two documents are cited together\n",
    "        by other documents. If at least one other document cites two documents in common these documents\n",
    "        are said to be co-cited\n",
    "        # (2) The produced list is non directed\n",
    "        \"\"\"\n",
    "        CC = []\n",
    "            \n",
    "        # Definition of all patent pairs\n",
    "        a = self.patent_list\n",
    "        all_patent_pairs = [(a[p1], a[p2]) for p1 in range(len(a)) for p2 in range(p1+1,len(a))]\n",
    "            \n",
    "        # Definition of the search algorithm\n",
    "        for patent in self.patent_list:\n",
    "            a = patent.patent_attributes[Config.VAR_CITED_DOCDB_FAM_ID]\n",
    "            if type(a)==list:\n",
    "                if len(a)>1:\n",
    "                    all_cited_patent_pairs = [(a[p1], a[p2]) \\\n",
    "                                              for p1 in range(len(a)) \\\n",
    "                                              for p2 in range(p1+1,len(a))]\n",
    "                    for pair in all_cited_patent_pairs:\n",
    "                        CC.append(pair)\n",
    "        \n",
    "        pairs = list(set(CC)) \n",
    "        \n",
    "        CC = []\n",
    "        for pair in pairs:\n",
    "            patent1 = [patent \\\n",
    "                       for patent in self.patent_list \\\n",
    "                       if patent.patent_attributes[Config.VAR_DOCDC_FAMILY_ID] == pair[0]]\n",
    "            patent2 = [patent \\\n",
    "                       for patent in self.patent_list \\\n",
    "                       if patent.patent_attributes[Config.VAR_DOCDC_FAMILY_ID] == pair[1]]\n",
    "\n",
    "            if len(patent1)>0:\n",
    "                patent1 = patent1[0]\n",
    "            else: patent1=np.nan\n",
    "\n",
    "            if len(patent2)>0:\n",
    "                patent2 = patent2[0]\n",
    "            else: patent2=np.nan\n",
    "\n",
    "            pair = (patent1, patent2)\n",
    "            CC.append(pair)\n",
    "\n",
    "        self.CC = [pair for pair in CC if (pair[0]==pair[0]) & (pair[1] == pair[1])]\n",
    "        return self\n",
    "     \n",
    "        \n",
    "    def _get_LC_citations(self):\n",
    "        \"\"\"\n",
    "        # (1) LC (longitudinal coupling). A cites a document that cites B\n",
    "        # (2) The produced list IS directed \n",
    "        # (3) Can be optimised\n",
    "        \"\"\"          \n",
    "        LC = []\n",
    "            \n",
    "        # Identifying all patents cited by a given patent A\n",
    "        for patent_A in self.patent_list:\n",
    "            cited_fam = patent_A.patent_attributes[Config.VAR_CITED_DOCDB_FAM_ID]\n",
    "            if type(cited_fam)==float:\n",
    "                    cited_fam = []\n",
    "                    cited_fam.append(patent_A.patent_attributes[Config.VAR_CITED_DOCDB_FAM_ID])\n",
    "            cited_patents = [patent \\\n",
    "                             for patent in self.patent_list \\\n",
    "                             if patent.patent_attributes[Config.VAR_DOCDC_FAMILY_ID] in cited_fam]\n",
    "                \n",
    "            # Identifying all patents cited by a patent cited by patent A\n",
    "            for cited_patent in cited_patents:\n",
    "                cited_fam = cited_patent.patent_attributes[Config.VAR_CITED_DOCDB_FAM_ID]\n",
    "                if type(cited_fam)==float:\n",
    "                    cited_fam = []\n",
    "                    cited_fam.append(cited_patent.patent_attributes[Config.VAR_CITED_DOCDB_FAM_ID])\n",
    "                cited_cited_patents = [patent \\\n",
    "                                       for patent in self.patent_list \\\n",
    "                                       if patent.patent_attributes[Config.VAR_DOCDC_FAMILY_ID] in cited_fam]\n",
    "                    \n",
    "                # Adding the pairs in the LC list\n",
    "                for patent_B in cited_cited_patents:\n",
    "                    LC.append((patent_A, patent_B))\n",
    "                    \n",
    "        # Removing duplicated items in the LC list\n",
    "        self.LC = list(set(LC)) \n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text processing\n",
    "\n",
    "- stemming\n",
    "- vectorisation with TF-IDF\n",
    "- measure cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextProcessing:\n",
    "    \"\"\"\n",
    "    Methods for text analysis and similarity measures\n",
    "    For the sake of computational power, we use these methods for patents in a citations pair only \n",
    "    \"\"\"\n",
    "    \n",
    "    def _stemming():\n",
    "        \"\"\"Reducing words to their stem word (semantic root)\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def _vectorize():\n",
    "        \"\"\"Vectorise the patents in a high dimention space\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def _similarity(p1, p2):\n",
    "        \"\"\"Measure the similiarity between a pair of linked patents pair = (p1, p2)\"\"\"\n",
    "        return 1 # for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the nlp-based patent network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildNetwork():\n",
    "    \"\"\"Builds a weighted network based on backwards citations and text similarity\"\"\"\n",
    "    \n",
    "    def _create_network(self):\n",
    "        \"\"\"Create the weighted and undirected network with igraph\"\"\"\n",
    "        \n",
    "        # defining all possible links between any pair of patents\n",
    "        links = self.direct_citations + self.CC + self.BC + self.LC\n",
    "        \n",
    "        def filter_symmetric_duplicates(l:list):\n",
    "            \"\"\"Code snippet to filter symmetric duplicates in a list of tuples\n",
    "            Eg [(1,2), (2,1)] -> [(1,2)]\"\"\"\n",
    "            seen = []\n",
    "            for pair in l:\n",
    "                if pair in seen:\n",
    "                    l.remove(pair)\n",
    "                seen.append(tuple(reversed(pair)))\n",
    "            return l\n",
    "        \n",
    "        # definition of the links\n",
    "        links = filter_symmetric_duplicates(links)\n",
    "        weighted_links = [(p1, p2, TextProcessing._similarity(p1, p2)) for (p1, p2) in links]\n",
    "        # creation of the graph\n",
    "        self.graph = Graph.TupleList(weighted_links, weights=True)\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary statistics (work in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummaryStatistics:\n",
    "    \"\"\"Summary statistics for the data section\"\"\"\n",
    "    # Can also help comparing before data cleaning and after!\n",
    "    \n",
    "    def _print_nb_patents(self):\n",
    "        \"\"\"Printing info\"\"\"\n",
    "        print('..Nb of patents:',len(self.data['_table_main_patent_infos']\\\n",
    "                                     [Config.VAR_APPLN_ID].unique().tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation (work in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Visualisation:\n",
    "    \"\"\"Visualisation methods\"\"\"\n",
    "    \n",
    "    def _draw_graph_with_communities(self):\n",
    "        comms = model.graph.community_multilevel()\n",
    "        plot(comms, mark_groups = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(Config, DataCleaning, NewMetrics, ReshapingToOOP, GetCitations,\n",
    "            TextProcessing, BuildNetwork, SummaryStatistics, Visualisation):\n",
    "    \"\"\"Creation of a model which inherits several building blocks\"\"\"\n",
    "    \n",
    "    # Attributes of the model\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        data: dict # datasets\n",
    "        patent_list: list # patent objects\n",
    "        patent_ids: list # list of patent ids contained in the model\n",
    "        patent_family_ids: list # list of DOCDB family ids contained in the model\n",
    "        direct_citations: list # directed list of simple citations\n",
    "        CC: list # undirected list of co-citations\n",
    "        BC: list # undirected list of bibliographical coupling\n",
    "        LC: list # directed list of longitudinal citations\n",
    "        graph: igraph.Graph # Igraph network\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def _input_data(self, data):\n",
    "        \"\"\"Getting the data in the model\"\"\"\n",
    "        self.data = data\n",
    "        \n",
    "    \n",
    "    def _compute_new_metrics(self):\n",
    "        \"\"\"Adding new variables in the dataset\"\"\"\n",
    "        self = NewMetrics._get_DOCDB_fam_cites_per_year(self)\n",
    "    \n",
    "        \n",
    "    def _data_cleaning(self):\n",
    "        \"\"\"Data cleaning using the DataCleaning class methods\"\"\"\n",
    "        self = DataCleaning._correct_JP_data(self)\n",
    "        self = DataCleaning._normalise(self)\n",
    "        self = DataCleaning._select_one_patent_per_family(self)\n",
    "        self = DataCleaning._select_breakthrough_patents(self)\n",
    "        \n",
    "        \n",
    "    def _fit_to_object_oriented_design(self):\n",
    "        \"\"\"We reshape the data from a tabular form to an object oriented form\"\"\"\n",
    "        self = ReshapingToOOP._create_patent_objects(self)\n",
    "        self = ReshapingToOOP._assign_data_to_patent_obj(self)\n",
    "    \n",
    "    \n",
    "    def _get_citations(self):\n",
    "        \"\"\"Identify direct and indirect citations that link the patents\"\"\"\n",
    "        self = GetCitations._get_direct_citations(self)\n",
    "        self = GetCitations._get_CC_citations(self)\n",
    "        self = GetCitations._get_BC_citations(self)\n",
    "        self = GetCitations._get_LC_citations(self)\n",
    "    \n",
    "    \n",
    "    def _compute_text_similarity(self):\n",
    "        \"\"\"Computing text similarities between linked patents\"\"\"\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def _build_patent_network(self):\n",
    "        \"\"\"We build the patent network (weighted directed graph)\"\"\"\n",
    "        self = BuildNetwork._create_network(self)\n",
    "    \n",
    "    def visualise(self):\n",
    "        \"\"\"Plot\"\"\"\n",
    "        self = Visualisation._draw_graph_with_communities(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# instantiation of the model\n",
    "model = Model()\n",
    "# fitting the model to the data\n",
    "model._input_data(data)\n",
    "# new metrics\n",
    "model._compute_new_metrics()\n",
    "# data cleaning\n",
    "model._data_cleaning()\n",
    "# reshape in an OOP manner before building the network\n",
    "model._fit_to_object_oriented_design()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving all types of citations\n",
    "model._get_citations()\n",
    "# Builing the NLP-based patent network\n",
    "model._build_patent_network()\n",
    "# Plot a visualisation\n",
    "model._visualise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1132614\n",
      "----\n",
      "200101745\n",
      "----\n",
      "1417409\n",
      "----\n",
      "1314885\n",
      "----\n",
      "177769\n",
      "----\n",
      "2025929\n",
      "----\n",
      "1995860\n",
      "----\n",
      "2129908\n",
      "----\n",
      "2163761\n",
      "----\n",
      "2283233\n",
      "----\n",
      "2345811\n",
      "----\n",
      "178197\n",
      "----\n",
      "201270045\n",
      "----\n",
      "201200554\n",
      "----\n",
      "201470474\n",
      "----\n",
      "2799709\n",
      "----\n",
      "2801720\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for patent in model.patent_list:\n",
    "    if patent.patent_attributes['appln_auth'] == 'DK':\n",
    "        print(patent.patent_attributes['publn_nr'])\n",
    "        print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'appln_id': 29571917,\n",
       " 'index_x': 13412,\n",
       " 'appln_id.1': [],\n",
       " 'appln_auth': 'JP',\n",
       " 'appln_nr': '8680890',\n",
       " 'appln_kind': 'U ',\n",
       " 'appln_filing_date': '1990-08-21',\n",
       " 'appln_filing_year': 1990,\n",
       " 'appln_nr_epodoc': 'JP19900086808U',\n",
       " 'appln_nr_original': '1990086808',\n",
       " 'ipr_type': 'UM',\n",
       " 'receiving_office': '  ',\n",
       " 'internat_appln_id': 0,\n",
       " 'int_phase': 'N',\n",
       " 'reg_phase': 'N',\n",
       " 'nat_phase': 'Y',\n",
       " 'earliest_filing_date': '1981-09-14',\n",
       " 'earliest_filing_year': 1981,\n",
       " 'earliest_filing_id': 18446242,\n",
       " 'earliest_publn_date': '1991-04-11',\n",
       " 'earliest_publn_year': 1991,\n",
       " 'earliest_pat_publn_id': 394335074,\n",
       " 'granted': 0,\n",
       " 'docdb_family_id': 8514692,\n",
       " 'inpadoc_family_id': 779343,\n",
       " 'docdb_family_size': 5,\n",
       " 'nb_citing_docdb_fam': 15,\n",
       " 'nb_applicants': 0,\n",
       " 'nb_inventors': 0,\n",
       " 'appln_id.2': [],\n",
       " 'appln_title_lg': [],\n",
       " 'appln_title': [],\n",
       " 'appln_id.3': [],\n",
       " 'appln_abstract_lg': [],\n",
       " 'appln_abstract': [],\n",
       " 'appln_id.4': 29571917.0,\n",
       " 'ipc_class_symbol': 'B63H  13/00',\n",
       " 'ipc_class_level': 'A',\n",
       " 'ipc_version': '2006-01-01',\n",
       " 'ipc_value': 'I',\n",
       " 'ipc_position': ' ',\n",
       " 'ipc_gener_auth': 'EP',\n",
       " 'appln_id.5': 29571917.0,\n",
       " 'nace2_code': 28.1,\n",
       " 'weight': 0.666667,\n",
       " 'pat_publn_id': 394335074,\n",
       " 'publn_auth': 'JP',\n",
       " 'publn_nr': 'H0337287',\n",
       " 'publn_nr_original': [],\n",
       " 'publn_kind': 'U ',\n",
       " 'appln_id.6': 29571917,\n",
       " 'publn_date': '1991-04-11',\n",
       " 'publn_lg': '  ',\n",
       " 'publn_first_grant': 0,\n",
       " 'publn_claims': 0,\n",
       " 'nb_citing_docdb_fam_by_year': 0.5357142857142857,\n",
       " 'index_y': 7795,\n",
       " 'docdb_family_id.1': 8514692.0,\n",
       " 'cited_docdb_family_id': [23518384.0,\n",
       "  14117387.0,\n",
       "  11929721.0,\n",
       "  11838519.0,\n",
       "  10146709.0,\n",
       "  10113522.0,\n",
       "  9727204.0,\n",
       "  9229272.0,\n",
       "  8930684.0,\n",
       "  7105621.0],\n",
       " 'index': 13412,\n",
       " 'cpc_class_symbol': ['B63H  13/00',\n",
       "  'E02B2017/0091',\n",
       "  'F03D  13/25',\n",
       "  'F05B2240/93',\n",
       "  'F05B2240/931',\n",
       "  'F05B2240/95',\n",
       "  'Y02E  10/727',\n",
       "  'Y02T  70/58'],\n",
       " 'cpc_scheme': 'CPC',\n",
       " 'cpc_version': ['2013-01-01', '2016-05-02'],\n",
       " 'cpc_value': ['I', 'A'],\n",
       " 'cpc_position': ['F', 'L'],\n",
       " 'cpc_gener_auth': '  ',\n",
       " 'person_id': [],\n",
       " 'applt_seq_nr': [],\n",
       " 'invt_seq_nr': [],\n",
       " 'person_id.1': [],\n",
       " 'person_name': [],\n",
       " 'person_address': [],\n",
       " 'person_ctry_code': [],\n",
       " 'doc_std_name_id': [],\n",
       " 'doc_std_name': [],\n",
       " 'psn_id': [],\n",
       " 'psn_name': [],\n",
       " 'psn_level': [],\n",
       " 'psn_sector': [],\n",
       " 'person_orig_id': [],\n",
       " 'person_id.2': [],\n",
       " 'source': [],\n",
       " 'source_version': [],\n",
       " 'name_freeform': [],\n",
       " 'last_name': [],\n",
       " 'first_name': [],\n",
       " 'middle_name': [],\n",
       " 'address_freeform': [],\n",
       " 'address_1': [],\n",
       " 'address_2': [],\n",
       " 'address_3': [],\n",
       " 'address_4': [],\n",
       " 'address_5': [],\n",
       " 'street': [],\n",
       " 'city': [],\n",
       " 'zip_code': [],\n",
       " 'state': [],\n",
       " 'person_ctry_code.1': [],\n",
       " 'residence_ctry_code': [],\n",
       " 'role': [],\n",
       " 'citing_docdb_families_ids': [44501726,\n",
       "  40499513,\n",
       "  40230605,\n",
       "  39690305,\n",
       "  30643259,\n",
       "  19766548,\n",
       "  19765290,\n",
       "  16018363,\n",
       "  9317938,\n",
       "  8543500,\n",
       "  8159382,\n",
       "  8149436,\n",
       "  6462010,\n",
       "  6394647,\n",
       "  55697311]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.patent_list[0].patent_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
